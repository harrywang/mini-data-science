{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This simple notebook shows how you can conduct automatic EDA with pandas_profiling and AutoML with autogluon. Although these packages can produce a very good performing model with very few lines of code, the results are generated in a \"blackbox\" fasion. It is still critical to learn EDA and machine learning algorithms/pipelines as we did in this tutorial to better understand the results, try other/better tuning methods, and develop additional custom models that are not covered by these packages. Therefore, a good workflow is to use these packages to get a quick overview of the data and models and then drill down to the parts that are of special interest and greater potential for better performance. \n",
    "\n",
    "In this example, the best performing model given by AutoGluon is XGBoost with 0.8324 accuracy, which is not part of scikit-learn package. Our manually-tuned best performing decision tree's accuray is 0.8258, which would be ranked #3 after ExtraTrees classfier (accuracy 08268) that we did not try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv data into pandas dataframe\n",
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pandas profiling report\n",
    "profile = ProfileReport(df, title=\"Titanic Pandas Profiling Report\")\n",
    "#profile = ProfileReport(df, title=\"Titanic Pandas Profiling Report\", minimal=True)  # this option turns off many expensive calculations for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 25/25 [00:13<00:00,  1.84it/s, Completed]\n",
      "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "Generate report structure: 100%|██████████| 1/1 [00:04<00:00,  4.28s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cb7d6499fe4482a2b4476d6c4059ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show report in notebook\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Partner, Mr. Austen</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113043</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>C124</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>734</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Berriman, Mr. William John</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28425</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Tikkanen, Mr. Juho</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101293</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>705</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hansen, Mr. Henrik Juul</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>350025</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>814</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Ebba Iris Alfrida</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Salkjelsvik, Miss. Anna Kristine</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343120</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cairns, Mr. Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113798</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>861</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hansen, Mr. Claus Peter</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>350026</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>436</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carter, Miss. Lucile Polk</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113760</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>White, Mr. Richard Frasar</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35281</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>D26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                Name  \\\n",
       "331          332         0       1                 Partner, Mr. Austen   \n",
       "733          734         0       2          Berriman, Mr. William John   \n",
       "382          383         0       3                  Tikkanen, Mr. Juho   \n",
       "704          705         0       3             Hansen, Mr. Henrik Juul   \n",
       "813          814         0       3  Andersson, Miss. Ebba Iris Alfrida   \n",
       "..           ...       ...     ...                                 ...   \n",
       "106          107         1       3    Salkjelsvik, Miss. Anna Kristine   \n",
       "270          271         0       1               Cairns, Mr. Alexander   \n",
       "860          861         0       3             Hansen, Mr. Claus Peter   \n",
       "435          436         1       1           Carter, Miss. Lucile Polk   \n",
       "102          103         0       1           White, Mr. Richard Frasar   \n",
       "\n",
       "        Sex   Age  SibSp  Parch             Ticket      Fare    Cabin Embarked  \n",
       "331    male  45.5      0      0             113043   28.5000     C124        S  \n",
       "733    male  23.0      0      0              28425   13.0000      NaN        S  \n",
       "382    male  32.0      0      0  STON/O 2. 3101293    7.9250      NaN        S  \n",
       "704    male  26.0      1      0             350025    7.8542      NaN        S  \n",
       "813  female   6.0      4      2             347082   31.2750      NaN        S  \n",
       "..      ...   ...    ...    ...                ...       ...      ...      ...  \n",
       "106  female  21.0      0      0             343120    7.6500      NaN        S  \n",
       "270    male   NaN      0      0             113798   31.0000      NaN        S  \n",
       "860    male  41.0      2      0             350026   14.1083      NaN        S  \n",
       "435  female  14.0      1      2             113760  120.0000  B96 B98        S  \n",
       "102    male  21.0      0      1              35281   77.2875      D26        S  \n",
       "\n",
       "[712 rows x 12 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into a training set and a test set for autogluon\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210706_205337/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210706_205337/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    712\n",
      "Train Data Columns: 11\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2262.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.25 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 7\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('object', ['text']) : 1 | ['Name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('float', [])                       :  2 | ['Age', 'Fare']\n",
      "\t\t('int', [])                         :  4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('int', ['binned', 'text_special']) : 12 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             :  8 | ['__nlp__.henry', '__nlp__.john', '__nlp__.master', '__nlp__.miss', '__nlp__.mr', ...]\n",
      "\t1.0s = Fit runtime\n",
      "\t11 features in original data used to generate 30 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 569, Val Rows: 143\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.5664\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.5594\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8252\t = Validation accuracy score\n",
      "\t5.77s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8322\t = Validation accuracy score\n",
      "\t4.11s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8042\t = Validation accuracy score\n",
      "\t0.72s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8182\t = Validation accuracy score\n",
      "\t0.88s\t = Training runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8322\t = Validation accuracy score\n",
      "\t1.56s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8252\t = Validation accuracy score\n",
      "\t0.94s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8252\t = Validation accuracy score\n",
      "\t0.8s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.8112\t = Validation accuracy score\n",
      "\t2.34s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8322\t = Validation accuracy score\n",
      "\t4.43s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.8112\t = Validation accuracy score\n",
      "\t8.85s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8392\t = Validation accuracy score\n",
      "\t0.67s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 33.82s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210706_205337/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0               XGBoost    0.832402   0.832168        0.061973       0.008468   4.425614                 0.061973                0.008468           4.425614            1       True         11\n",
      "1        ExtraTreesGini    0.826816   0.825175        0.095502       0.102658   0.940352                 0.095502                0.102658           0.940352            1       True          8\n",
      "2            LightGBMXT    0.821229   0.825175        0.024099       0.015579   5.769226                 0.024099                0.015579           5.769226            1       True          3\n",
      "3        ExtraTreesEntr    0.821229   0.825175        0.104361       0.075775   0.803593                 0.104361                0.075775           0.803593            1       True          9\n",
      "4      RandomForestGini    0.821229   0.804196        0.131723       0.081844   0.720125                 0.131723                0.081844           0.720125            1       True          5\n",
      "5      RandomForestEntr    0.821229   0.818182        0.168041       0.136883   0.884040                 0.168041                0.136883           0.884040            1       True          6\n",
      "6              CatBoost    0.815642   0.832168        0.036006       0.011745   1.564894                 0.036006                0.011745           1.564894            1       True          7\n",
      "7       NeuralNetFastAI    0.815642   0.811189        0.062542       0.059094   2.343514                 0.062542                0.059094           2.343514            1       True         10\n",
      "8              LightGBM    0.810056   0.832168        0.033771       0.013347   4.112265                 0.033771                0.013347           4.112265            1       True          4\n",
      "9   WeightedEnsemble_L2    0.810056   0.839161        0.312834       0.172937  18.944484                 0.006689                0.001203           0.668341            2       True         13\n",
      "10        LightGBMLarge    0.804469   0.811189        0.042360       0.013036   8.854224                 0.042360                0.013036           8.854224            1       True         12\n",
      "11       KNeighborsDist    0.648045   0.559441        0.007773       0.007185   0.014580                 0.007773                0.007185           0.014580            1       True          2\n",
      "12       KNeighborsUnif    0.625698   0.566434        0.005408       0.010327   0.010651                 0.005408                0.010327           0.010651            1       True          1\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "predictor = TabularPredictor(label='Survived').fit(train_data)\n",
    "leaderboard = predictor.leaderboard(test_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24c36f38f51f2c059798fb8a6f6646f59da8defeb4792367359bef4d1f7f3be9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}