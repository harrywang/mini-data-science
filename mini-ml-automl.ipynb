{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This simple notebook shows how you can conduct automatic EDA with pandas_profiling and AutoML with autogluon. \n",
    "\n",
    "Although these packages can produce a very good performing model with very few lines of code, the results are generated in a \"blackbox\" fasion. It is still critical to learn EDA and machine learning algorithms/pipelines as we did in this tutorial to better understand the results, try other/better tuning methods, and develop additional custom models that are not covered by these packages. \n",
    "\n",
    "Therefore, a good workflow is to use these packages to get a quick overview of the data and models and then drill down to the parts that are of special interest and greater potential for better performance. \n",
    "\n",
    "In this example, the best performing model given by AutoGluon is XGBoost with 0.8324 accuracy, which is not part of scikit-learn package. Our manually-tuned best performing decision tree's accuray is 0.8258, which would be ranked #3 after ExtraTrees classfier (accuracy 08268) that we did not try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv data into pandas dataframe\n",
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pandas profiling report\n",
    "profile = ProfileReport(df, title=\"Titanic Pandas Profiling Report\")\n",
    "#profile = ProfileReport(df, title=\"Titanic Pandas Profiling Report\", minimal=True)  # this option turns off many expensive calculations for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 25/25 [00:10<00:00,  2.31it/s, Completed]\n",
      "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "Generate report structure: 100%|██████████| 1/1 [00:08<00:00,  8.41s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115076ad190542cb8428819779527e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show report in notebook\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step is optional - I keep it here to be consistent with the tutorial\n",
    "# dropping unimportant features, such as passenger id, name, ticket number and cabin number\n",
    "df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
       "331         0       1    male  45.5      0      0   28.5000        S\n",
       "733         0       2    male  23.0      0      0   13.0000        S\n",
       "382         0       3    male  32.0      0      0    7.9250        S\n",
       "704         0       3    male  26.0      1      0    7.8542        S\n",
       "813         0       3  female   6.0      4      2   31.2750        S\n",
       "..        ...     ...     ...   ...    ...    ...       ...      ...\n",
       "106         1       3  female  21.0      0      0    7.6500        S\n",
       "270         0       1    male   NaN      0      0   31.0000        S\n",
       "860         0       3    male  41.0      2      0   14.1083        S\n",
       "435         1       1  female  14.0      1      2  120.0000        S\n",
       "102         0       1    male  21.0      0      1   77.2875        S\n",
       "\n",
       "[712 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into a training set and a test set for autogluon\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210712_200740/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210712_200740/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    712\n",
      "Train Data Columns: 7\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1711.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.rename_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])    : 3 | ['Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', []) : 2 | ['Sex', 'Embarked']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 2 | ['Sex', 'Embarked']\n",
      "\t\t('float', [])    : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])      : 3 | ['Pclass', 'SibSp', 'Parch']\n",
      "\t0.2s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 569, Val Rows: 143\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.6294\t = Validation accuracy score\n",
      "\t0.04s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.6154\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8182\t = Validation accuracy score\n",
      "\t6.82s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8112\t = Validation accuracy score\n",
      "\t0.85s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7692\t = Validation accuracy score\n",
      "\t0.74s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7552\t = Validation accuracy score\n",
      "\t0.85s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8182\t = Validation accuracy score\n",
      "\t1.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7413\t = Validation accuracy score\n",
      "\t0.72s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7343\t = Validation accuracy score\n",
      "\t0.66s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7832\t = Validation accuracy score\n",
      "\t5.34s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7972\t = Validation accuracy score\n",
      "\t1.9s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7902\t = Validation accuracy score\n",
      "\t7.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8322\t = Validation accuracy score\n",
      "\t0.63s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 28.57s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210712_200740/\")\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.set_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.rename_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0        ExtraTreesEntr    0.826816   0.734266        0.092608       0.063413   0.656698                 0.092608                0.063413           0.656698            1       True          9\n",
      "1      RandomForestGini    0.826816   0.769231        0.103510       0.105403   0.740338                 0.103510                0.105403           0.740338            1       True          5\n",
      "2      RandomForestEntr    0.826816   0.755245        0.110604       0.089262   0.847276                 0.110604                0.089262           0.847276            1       True          6\n",
      "3        ExtraTreesGini    0.821229   0.741259        0.092251       0.069837   0.715123                 0.092251                0.069837           0.715123            1       True          8\n",
      "4            LightGBMXT    0.810056   0.818182        0.018182       0.026126   6.821703                 0.018182                0.026126           6.821703            1       True          3\n",
      "5              CatBoost    0.810056   0.818182        0.019531       0.009604   0.996431                 0.019531                0.009604           0.996431            1       True          7\n",
      "6   WeightedEnsemble_L2    0.810056   0.832168        0.152723       0.126689  16.176822                 0.005069                0.001098           0.625589            2       True         13\n",
      "7               XGBoost    0.787709   0.797203        0.035644       0.015953   1.901077                 0.035644                0.015953           1.901077            1       True         11\n",
      "8       NeuralNetFastAI    0.782123   0.783217        0.033407       0.041460   5.338948                 0.033407                0.041460           5.338948            1       True         10\n",
      "9              LightGBM    0.776536   0.811189        0.007824       0.006307   0.846549                 0.007824                0.006307           0.846549            1       True          4\n",
      "10        LightGBMLarge    0.770950   0.790210        0.011942       0.006132   7.013820                 0.011942                0.006132           7.013820            1       True         12\n",
      "11       KNeighborsDist    0.675978   0.615385        0.005748       0.013892   0.004156                 0.005748                0.013892           0.004156            1       True          2\n",
      "12       KNeighborsUnif    0.670391   0.629371        0.004515       0.032677   0.035712                 0.004515                0.032677           0.035712            1       True          1\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "predictor = TabularPredictor(label='Survived').fit(train_data)\n",
    "leaderboard = predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "709         1       3    male   NaN      1      1  15.2458        C\n",
       "439         0       2    male  31.0      0      0  10.5000        S\n",
       "840         0       3    male  20.0      0      0   7.9250        S\n",
       "720         1       2  female   6.0      0      1  33.0000        S\n",
       "39          1       3  female  14.0      1      0  11.2417        C\n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...\n",
       "433         0       3    male  17.0      0      0   7.1250        S\n",
       "773         0       3    male   NaN      0      0   7.2250        C\n",
       "25          1       3  female  38.0      1      5  31.3875        S\n",
       "84          1       2  female  17.0      0      0  10.5000        S\n",
       "10          1       3  female   4.0      1      1  16.7000        S\n",
       "\n",
       "[179 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger1 = pd.DataFrame(\n",
    "    {   \n",
    "        'Pclass': [3],\n",
    "        'Sex': ['male'], \n",
    "        'Age': [23],\n",
    "        'SibSp': [0],\n",
    "        'Parch': [0],\n",
    "        'Fare': [5.5],\n",
    "        'Embarked': ['C'],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.set_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.rename_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict one\n",
    "predictor.predict(passenger1) # default is using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.set_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.rename_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict using other model\n",
    "predictor.predict(passenger1, model='RandomForestEntr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210712_200809/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210712_200809/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    712\n",
      "Train Data Columns: 7\n",
      "Preprocessing data ...\n",
      "Warning: Ignoring 2 (out of 712) training examples for which the label value in column 'Embarked' is missing\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['S', 'C', 'Q']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1991.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.rename_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])    : 4 | ['Survived', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', []) : 1 | ['Sex']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['Sex']\n",
      "\t\t('float', [])    : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])      : 4 | ['Survived', 'Pclass', 'SibSp', 'Parch']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 59.83s of the 59.82s of remaining time.\n",
      "\t-1.3045\t = Validation log_loss score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 59.79s of the 59.79s of remaining time.\n",
      "\t-1.3159\t = Validation log_loss score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 59.75s of the 59.75s of remaining time.\n",
      "\t-0.6688\t = Validation log_loss score\n",
      "\t9.11s\t = Training runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 50.29s of the 50.28s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 296. Best iteration is:\n",
      "\t[275]\ttrain_set's multi_logloss: 0.332093\tvalid_set's multi_logloss: 0.518629\n",
      "\tRan out of time, early stopping on iteration 93. Best iteration is:\n",
      "\t[91]\ttrain_set's multi_logloss: 0.464687\tvalid_set's multi_logloss: 0.535519\n",
      "\tRan out of time, early stopping on iteration 110. Best iteration is:\n",
      "\t[110]\ttrain_set's multi_logloss: 0.434824\tvalid_set's multi_logloss: 0.582321\n",
      "\tRan out of time, early stopping on iteration 106. Best iteration is:\n",
      "\t[95]\ttrain_set's multi_logloss: 0.45111\tvalid_set's multi_logloss: 0.611061\n",
      "\tRan out of time, early stopping on iteration 704. Best iteration is:\n",
      "\t[673]\ttrain_set's multi_logloss: 0.214187\tvalid_set's multi_logloss: 0.453957\n",
      "\t-0.5515\t = Validation log_loss score\n",
      "\t40.65s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 9.06s of the 9.06s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 128. Best iteration is:\n",
      "\t[86]\ttrain_set's multi_logloss: 0.158671\tvalid_set's multi_logloss: 0.375218\n",
      "\tRan out of time, early stopping on iteration 9. Best iteration is:\n",
      "\t[9]\ttrain_set's multi_logloss: 0.533423\tvalid_set's multi_logloss: 0.564658\n",
      "\tRan out of time, early stopping on iteration 35. Best iteration is:\n",
      "\t[35]\ttrain_set's multi_logloss: 0.316621\tvalid_set's multi_logloss: 0.490361\n",
      "\tRan out of time, early stopping on iteration 20. Best iteration is:\n",
      "\t[20]\ttrain_set's multi_logloss: 0.416247\tvalid_set's multi_logloss: 0.513268\n",
      "\tRan out of time, early stopping on iteration 41. Best iteration is:\n",
      "\t[41]\ttrain_set's multi_logloss: 0.288124\tvalid_set's multi_logloss: 0.385209\n",
      "\tRan out of time, early stopping on iteration 70. Best iteration is:\n",
      "\t[70]\ttrain_set's multi_logloss: 0.185676\tvalid_set's multi_logloss: 0.472283\n",
      "\tRan out of time, early stopping on iteration 37. Best iteration is:\n",
      "\t[37]\ttrain_set's multi_logloss: 0.310533\tvalid_set's multi_logloss: 0.407297\n",
      "\t-0.4584\t = Validation log_loss score\n",
      "\t8.67s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 0.18s of the 0.18s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 48 due to low time. Expected time usage reduced from 1.1s -> 0.2s...\n",
      "\t-0.6238\t = Validation log_loss score\n",
      "\t0.15s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.83s of the -0.04s of remaining time.\n",
      "\t-0.4373\t = Validation log_loss score\n",
      "\t0.78s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 60.86s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210712_200809/\")\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.set_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.rename_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-0.496261</td>\n",
       "      <td>-0.458405</td>\n",
       "      <td>0.173804</td>\n",
       "      <td>0.056279</td>\n",
       "      <td>8.672698</td>\n",
       "      <td>0.173804</td>\n",
       "      <td>0.056279</td>\n",
       "      <td>8.672698</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.500019</td>\n",
       "      <td>-0.437330</td>\n",
       "      <td>0.264145</td>\n",
       "      <td>0.090508</td>\n",
       "      <td>9.605694</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.783969</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-0.578152</td>\n",
       "      <td>-0.551534</td>\n",
       "      <td>0.382732</td>\n",
       "      <td>0.103050</td>\n",
       "      <td>40.647673</td>\n",
       "      <td>0.382732</td>\n",
       "      <td>0.103050</td>\n",
       "      <td>40.647673</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>-0.620727</td>\n",
       "      <td>-0.623831</td>\n",
       "      <td>0.046487</td>\n",
       "      <td>0.027569</td>\n",
       "      <td>0.146362</td>\n",
       "      <td>0.046487</td>\n",
       "      <td>0.027569</td>\n",
       "      <td>0.146362</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-0.709866</td>\n",
       "      <td>-0.668783</td>\n",
       "      <td>0.707407</td>\n",
       "      <td>0.192682</td>\n",
       "      <td>9.112587</td>\n",
       "      <td>0.707407</td>\n",
       "      <td>0.192682</td>\n",
       "      <td>9.112587</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-1.909044</td>\n",
       "      <td>-1.304484</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>0.009870</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>0.009870</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-1.953941</td>\n",
       "      <td>-1.315919</td>\n",
       "      <td>0.039920</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.039920</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_test  score_val  pred_time_test  \\\n",
       "0          LightGBM_BAG_L1   -0.496261  -0.458405        0.173804   \n",
       "1      WeightedEnsemble_L2   -0.500019  -0.437330        0.264145   \n",
       "2        LightGBMXT_BAG_L1   -0.578152  -0.551534        0.382732   \n",
       "3  RandomForestGini_BAG_L1   -0.620727  -0.623831        0.046487   \n",
       "4   NeuralNetFastAI_BAG_L1   -0.709866  -0.668783        0.707407   \n",
       "5    KNeighborsUnif_BAG_L1   -1.909044  -1.304484        0.007542   \n",
       "6    KNeighborsDist_BAG_L1   -1.953941  -1.315919        0.039920   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.056279   8.672698                 0.173804                0.056279   \n",
       "1       0.090508   9.605694                 0.003934                0.001473   \n",
       "2       0.103050  40.647673                 0.382732                0.103050   \n",
       "3       0.027569   0.146362                 0.046487                0.027569   \n",
       "4       0.192682   9.112587                 0.707407                0.192682   \n",
       "5       0.008119   0.009870                 0.007542                0.008119   \n",
       "6       0.005187   0.002665                 0.039920                0.005187   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           8.672698            1       True          5  \n",
       "1           0.783969            2       True          7  \n",
       "2          40.647673            1       True          4  \n",
       "3           0.146362            1       True          6  \n",
       "4           9.112587            1       True          3  \n",
       "5           0.009870            1       True          1  \n",
       "6           0.002665            1       True          2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a multiclass classification using different metric \n",
    "time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "label = 'Embarked'\n",
    "metric = 'log_loss'  # specify your evaluation metric here, most important classification metric based on probabilities, the lower the better\n",
    "presets = 'best_quality' # this allows AutoGluon to automatically construct powerful model ensembles based on stacking/bagging\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets=presets)\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210712_200912/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210712_200912/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    712\n",
      "Train Data Columns: 7\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (512.3292, 0.0, 32.58628, 51.96953)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2247.04 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.rename_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1 | ['Age']\n",
      "\t\t('int', [])    : 4 | ['Survived', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', []) : 2 | ['Sex', 'Embarked']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 2 | ['Sex', 'Embarked']\n",
      "\t\t('float', [])    : 1 | ['Age']\n",
      "\t\t('int', [])      : 4 | ['Survived', 'Pclass', 'SibSp', 'Parch']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 59.89s of the 59.88s of remaining time.\n",
      "\t-42.442\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 59.84s of the 59.83s of remaining time.\n",
      "\t-43.9999\t = Validation root_mean_squared_error score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 59.78s of the 59.78s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's rmse: 24.1369\tvalid_set's rmse: 38.9681\n",
      "[2000]\ttrain_set's rmse: 20.4021\tvalid_set's rmse: 37.4501\n",
      "[3000]\ttrain_set's rmse: 18.3425\tvalid_set's rmse: 37.0559\n",
      "[4000]\ttrain_set's rmse: 16.9427\tvalid_set's rmse: 36.8768\n",
      "[5000]\ttrain_set's rmse: 15.8747\tvalid_set's rmse: 36.7854\n",
      "[1000]\ttrain_set's rmse: 22.1435\tvalid_set's rmse: 43.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-34.3276\t = Validation root_mean_squared_error score\n",
      "\t27.38s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 31.9s of the 31.89s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 371. Best iteration is:\n",
      "\t[257]\ttrain_set's rmse: 25.2884\tvalid_set's rmse: 27.4423\n",
      "\tRan out of time, early stopping on iteration 136. Best iteration is:\n",
      "\t[136]\ttrain_set's rmse: 27.0032\tvalid_set's rmse: 45.0637\n",
      "\tRan out of time, early stopping on iteration 97. Best iteration is:\n",
      "\t[95]\ttrain_set's rmse: 28.6812\tvalid_set's rmse: 41.2727\n",
      "\tRan out of time, early stopping on iteration 180. Best iteration is:\n",
      "\t[139]\ttrain_set's rmse: 28.9203\tvalid_set's rmse: 21.1583\n",
      "\tRan out of time, early stopping on iteration 303. Best iteration is:\n",
      "\t[246]\ttrain_set's rmse: 22.2556\tvalid_set's rmse: 42.6277\n",
      "\t-33.8552\t = Validation root_mean_squared_error score\n",
      "\t30.16s\t = Training runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1.41s of the 1.4s of remaining time.\n",
      "\t-37.67\t = Validation root_mean_squared_error score\n",
      "\t0.81s\t = Training runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 0.36s of the 0.35s of remaining time.\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 0.29s of the 0.28s of remaining time.\n",
      "\t-38.2467\t = Validation root_mean_squared_error score\n",
      "\t0.67s\t = Training runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.89s of the -0.67s of remaining time.\n",
      "\t-33.6218\t = Validation root_mean_squared_error score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 61.1s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210712_200912/\")\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.set_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n",
      "/Users/harrywang/sandbox/mini-ml/venv/lib/python3.8/site-packages/pandas/core/arrays/categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.rename_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-35.332268</td>\n",
       "      <td>-33.855177</td>\n",
       "      <td>0.125364</td>\n",
       "      <td>0.135500</td>\n",
       "      <td>30.155718</td>\n",
       "      <td>0.125364</td>\n",
       "      <td>0.135500</td>\n",
       "      <td>30.155718</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-35.335685</td>\n",
       "      <td>-34.327552</td>\n",
       "      <td>0.311582</td>\n",
       "      <td>0.101881</td>\n",
       "      <td>27.380675</td>\n",
       "      <td>0.311582</td>\n",
       "      <td>0.101881</td>\n",
       "      <td>27.380675</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-35.337402</td>\n",
       "      <td>-33.621813</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.424035</td>\n",
       "      <td>58.577053</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.366925</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-39.355784</td>\n",
       "      <td>-37.670003</td>\n",
       "      <td>0.094323</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.811818</td>\n",
       "      <td>0.094323</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.811818</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-39.573354</td>\n",
       "      <td>-42.442024</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.020595</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.020595</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-40.940658</td>\n",
       "      <td>-43.999949</td>\n",
       "      <td>0.024063</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.024063</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-45.746227</td>\n",
       "      <td>-38.246714</td>\n",
       "      <td>0.118884</td>\n",
       "      <td>0.183216</td>\n",
       "      <td>0.673735</td>\n",
       "      <td>0.118884</td>\n",
       "      <td>0.183216</td>\n",
       "      <td>0.673735</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val  pred_time_test  \\\n",
       "0         LightGBM_BAG_L1  -35.332268 -33.855177        0.125364   \n",
       "1       LightGBMXT_BAG_L1  -35.335685 -34.327552        0.311582   \n",
       "2     WeightedEnsemble_L2  -35.337402 -33.621813        0.558324   \n",
       "3  RandomForestMSE_BAG_L1  -39.355784 -37.670003        0.094323   \n",
       "4   KNeighborsUnif_BAG_L1  -39.573354 -42.442024        0.009333   \n",
       "5   KNeighborsDist_BAG_L1  -40.940658 -43.999949        0.024063   \n",
       "6    ExtraTreesMSE_BAG_L1  -45.746227 -38.246714        0.118884   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.135500  30.155718                 0.125364                0.135500   \n",
       "1       0.101881  27.380675                 0.311582                0.101881   \n",
       "2       0.424035  58.577053                 0.002495                0.003437   \n",
       "3       0.150841   0.811818                 0.094323                0.150841   \n",
       "4       0.020595   0.007820                 0.009333                0.020595   \n",
       "5       0.027958   0.003279                 0.024063                0.027958   \n",
       "6       0.183216   0.673735                 0.118884                0.183216   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0          30.155718            1       True          4  \n",
       "1          27.380675            1       True          3  \n",
       "2           0.366925            2       True          7  \n",
       "3           0.811818            1       True          5  \n",
       "4           0.007820            1       True          1  \n",
       "5           0.003279            1       True          2  \n",
       "6           0.673735            1       True          6  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a regression problem\n",
    "time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "label = 'Fare'\n",
    "metric = 'root_mean_squared_error'  # RMSE is the default metric for regression problem\n",
    "presets = 'best_quality' # this allows AutoGluon to automatically construct powerful model ensembles based on stacking/bagging\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets=presets)\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60983cc5b4e6e68ad045e44d0cff1b681bb235747c6ffab0a64a1207595c05a7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}