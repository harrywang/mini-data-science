{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This simple notebook shows how you can conduct automatic EDA with pandas_profiling and AutoML with autogluon. Although these packages can produce a very good performing model with very few lines of code, the results are generated in a \"blackbox\" fasion. It is still critical to learn EDA and machine learning algorithms/pipelines as we did in this tutorial to better understand the results, try other/better tuning methods, and develop additional custom models that are not covered by these packages. Therefore, a good workflow is to use these packages to get a quick overview of the data and models and then drill down to the parts that are of special interest and greater potential for better performance. \n",
    "\n",
    "In this example, the best performing model given by AutoGluon is XGBoost with 0.8324 accuracy, which is not part of scikit-learn package. Our manually-tuned best performing decision tree's accuray is 0.8258, which would be ranked #3 after ExtraTrees classfier (accuracy 08268) that we did not try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# read csv data into pandas dataframe\n",
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pandas profiling report\n",
    "profile = ProfileReport(df, title=\"Titanic Pandas Profiling Report\")\n",
    "#profile = ProfileReport(df, title=\"Titanic Pandas Profiling Report\", minimal=True)  # this option turns off many expensive calculations for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 25/25 [00:07<00:00,  3.19it/s, Completed]\n",
      "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/pandas_profiling/report/formatters.py:260: DeprecationWarning: 'jinja2.escape' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.escape' instead.\n",
      "  return str(escape(value))\n",
      "Generate report structure: 100%|██████████| 1/1 [00:04<00:00,  4.56s/it]\n",
      "                                                     "
     ]
    }
   ],
   "source": [
    "# show report in notebook\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step is optional - I keep it here to be consistent with the tutorial\n",
    "# dropping unimportant features, such as passenger id, name, ticket number and cabin number\n",
    "df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
       "331         0       1    male  45.5      0      0   28.5000        S\n",
       "733         0       2    male  23.0      0      0   13.0000        S\n",
       "382         0       3    male  32.0      0      0    7.9250        S\n",
       "704         0       3    male  26.0      1      0    7.8542        S\n",
       "813         0       3  female   6.0      4      2   31.2750        S\n",
       "..        ...     ...     ...   ...    ...    ...       ...      ...\n",
       "106         1       3  female  21.0      0      0    7.6500        S\n",
       "270         0       1    male   NaN      0      0   31.0000        S\n",
       "860         0       3    male  41.0      2      0   14.1083        S\n",
       "435         1       1  female  14.0      1      2  120.0000        S\n",
       "102         0       1    male  21.0      0      1   77.2875        S\n",
       "\n",
       "[712 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into a training set and a test set for autogluon\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210708_230838/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210708_230838/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    712\n",
      "Train Data Columns: 7\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1954.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])    : 3 | ['Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', []) : 2 | ['Sex', 'Embarked']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 2 | ['Sex', 'Embarked']\n",
      "\t\t('float', [])    : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])      : 3 | ['Pclass', 'SibSp', 'Parch']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 569, Val Rows: 143\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.6294\t = Validation accuracy score\n",
      "\t0.02s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.6154\t = Validation accuracy score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8182\t = Validation accuracy score\n",
      "\t8.92s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8112\t = Validation accuracy score\n",
      "\t5.15s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7692\t = Validation accuracy score\n",
      "\t0.87s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7552\t = Validation accuracy score\n",
      "\t0.92s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8182\t = Validation accuracy score\n",
      "\t1.38s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7413\t = Validation accuracy score\n",
      "\t0.95s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7343\t = Validation accuracy score\n",
      "\t0.93s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.8112\t = Validation accuracy score\n",
      "\t3.47s\t = Training runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7972\t = Validation accuracy score\n",
      "\t8.84s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\tWarning: Exception caused NeuralNetMXNet to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7902\t = Validation accuracy score\n",
      "\t5.55s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8322\t = Validation accuracy score\n",
      "\t0.7s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 39.96s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210708_230838/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      RandomForestEntr    0.826816   0.755245        0.102937       0.097430   0.918301                 0.102937                0.097430           0.918301            1       True          6\n",
      "1      RandomForestGini    0.826816   0.769231        0.109808       0.099157   0.869003                 0.109808                0.099157           0.869003            1       True          5\n",
      "2        ExtraTreesEntr    0.826816   0.734266        0.186973       0.090966   0.932679                 0.186973                0.090966           0.932679            1       True          9\n",
      "3        ExtraTreesGini    0.821229   0.741259        0.217060       0.102577   0.949540                 0.217060                0.102577           0.949540            1       True          8\n",
      "4   WeightedEnsemble_L2    0.821229   0.832168        0.549430       0.432790  34.524664                 0.010156                0.001091           0.704030            2       True         13\n",
      "5       NeuralNetFastAI    0.815642   0.811189        0.038021       0.172731   3.468807                 0.038021                0.172731           3.468807            1       True         10\n",
      "6              CatBoost    0.810056   0.818182        0.006961       0.030154   1.379392                 0.006961                0.030154           1.379392            1       True          7\n",
      "7            LightGBMXT    0.810056   0.818182        0.014268       0.011384   8.917403                 0.014268                0.011384           8.917403            1       True          3\n",
      "8               XGBoost    0.787709   0.797203        0.038183       0.014514   8.836266                 0.038183                0.014514           8.836266            1       True         11\n",
      "9              LightGBM    0.776536   0.811189        0.024593       0.011341   5.145799                 0.024593                0.011341           5.145799            1       True          4\n",
      "10        LightGBMLarge    0.770950   0.790210        0.013833       0.010004   5.551399                 0.013833                0.010004           5.551399            1       True         12\n",
      "11       KNeighborsDist    0.675978   0.615385        0.007435       0.015726   0.011255                 0.007435                0.015726           0.011255            1       True          2\n",
      "12       KNeighborsUnif    0.670391   0.629371        0.006344       0.018182   0.018740                 0.006344                0.018182           0.018740            1       True          1\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "predictor = TabularPredictor(label='Survived').fit(train_data)\n",
    "leaderboard = predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "709         1       3    male   NaN      1      1  15.2458        C\n",
       "439         0       2    male  31.0      0      0  10.5000        S\n",
       "840         0       3    male  20.0      0      0   7.9250        S\n",
       "720         1       2  female   6.0      0      1  33.0000        S\n",
       "39          1       3  female  14.0      1      0  11.2417        C\n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...\n",
       "433         0       3    male  17.0      0      0   7.1250        S\n",
       "773         0       3    male   NaN      0      0   7.2250        C\n",
       "25          1       3  female  38.0      1      5  31.3875        S\n",
       "84          1       2  female  17.0      0      0  10.5000        S\n",
       "10          1       3  female   4.0      1      1  16.7000        S\n",
       "\n",
       "[179 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger1 = pd.DataFrame(\n",
    "    {   \n",
    "        'Pclass': [3],\n",
    "        'Sex': ['male'], \n",
    "        'Age': [23],\n",
    "        'SibSp': [0],\n",
    "        'Parch': [0],\n",
    "        'Fare': [5.5],\n",
    "        'Embarked': ['C'],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict one\n",
    "predictor.predict(passenger1) # default is using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywang/sandbox/mini-data-science/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict using other model\n",
    "predictor.predict(passenger1, model='RandomForestEntr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210708_234314/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210708_234314/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    712\n",
      "Train Data Columns: 7\n",
      "Preprocessing data ...\n",
      "Warning: Ignoring 2 (out of 712) training examples for which the label value in column 'Embarked' is missing\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['S', 'C', 'Q']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2131.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])    : 4 | ['Survived', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', []) : 1 | ['Sex']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['Sex']\n",
      "\t\t('float', [])    : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])      : 4 | ['Survived', 'Pclass', 'SibSp', 'Parch']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 59.73s of the 59.71s of remaining time.\n",
      "\t-1.3045\t = Validation log_loss score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 59.63s of the 59.62s of remaining time.\n",
      "\t-1.3159\t = Validation log_loss score\n",
      "\t0.02s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 59.55s of the 59.53s of remaining time.\n",
      "\t-0.6673\t = Validation log_loss score\n",
      "\t16.08s\t = Training runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 43.04s of the 43.02s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain_set's multi_logloss: 0.161396\tvalid_set's multi_logloss: 0.441986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5362\t = Validation log_loss score\n",
      "\t28.63s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 13.5s of the 13.48s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 40. Best iteration is:\n",
      "\t[40]\ttrain_set's multi_logloss: 0.307531\tvalid_set's multi_logloss: 0.437246\n",
      "\tRan out of time, early stopping on iteration 32. Best iteration is:\n",
      "\t[32]\ttrain_set's multi_logloss: 0.338584\tvalid_set's multi_logloss: 0.440698\n",
      "\tRan out of time, early stopping on iteration 37. Best iteration is:\n",
      "\t[36]\ttrain_set's multi_logloss: 0.311667\tvalid_set's multi_logloss: 0.490231\n",
      "\tRan out of time, early stopping on iteration 167. Best iteration is:\n",
      "\t[63]\ttrain_set's multi_logloss: 0.20529\tvalid_set's multi_logloss: 0.462301\n",
      "\tRan out of time, early stopping on iteration 197. Best iteration is:\n",
      "\t[64]\ttrain_set's multi_logloss: 0.208921\tvalid_set's multi_logloss: 0.390644\n",
      "\t-0.4277\t = Validation log_loss score\n",
      "\t12.25s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 0.91s of the 0.89s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 138 due to low time. Expected time usage reduced from 2.0s -> 0.9s...\n",
      "\t-0.5339\t = Validation log_loss score\n",
      "\t0.54s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 0.27s of the 0.25s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 82 due to low time. Expected time usage reduced from 1.0s -> 0.3s...\n",
      "\t-0.6135\t = Validation log_loss score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.73s of the -0.18s of remaining time.\n",
      "\t-0.4202\t = Validation log_loss score\n",
      "\t1.19s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 61.41s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210708_234314/\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-0.468011</td>\n",
       "      <td>-0.427716</td>\n",
       "      <td>0.285134</td>\n",
       "      <td>0.087342</td>\n",
       "      <td>12.252498</td>\n",
       "      <td>0.285134</td>\n",
       "      <td>0.087342</td>\n",
       "      <td>12.252498</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.479886</td>\n",
       "      <td>-0.420161</td>\n",
       "      <td>0.396357</td>\n",
       "      <td>0.154566</td>\n",
       "      <td>14.005736</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>1.191968</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>-0.568357</td>\n",
       "      <td>-0.613459</td>\n",
       "      <td>0.053644</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.357141</td>\n",
       "      <td>0.053644</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.357141</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-0.570314</td>\n",
       "      <td>-0.536182</td>\n",
       "      <td>1.075846</td>\n",
       "      <td>0.108582</td>\n",
       "      <td>28.633922</td>\n",
       "      <td>1.075846</td>\n",
       "      <td>0.108582</td>\n",
       "      <td>28.633922</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>-0.618937</td>\n",
       "      <td>-0.533887</td>\n",
       "      <td>0.083508</td>\n",
       "      <td>0.057316</td>\n",
       "      <td>0.544376</td>\n",
       "      <td>0.083508</td>\n",
       "      <td>0.057316</td>\n",
       "      <td>0.544376</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-0.715127</td>\n",
       "      <td>-0.667328</td>\n",
       "      <td>0.642130</td>\n",
       "      <td>0.231859</td>\n",
       "      <td>16.081263</td>\n",
       "      <td>0.642130</td>\n",
       "      <td>0.231859</td>\n",
       "      <td>16.081263</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-1.909044</td>\n",
       "      <td>-1.304484</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.037288</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.037288</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-1.953941</td>\n",
       "      <td>-1.315919</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.007637</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.007637</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_test  score_val  pred_time_test  \\\n",
       "0          LightGBM_BAG_L1   -0.468011  -0.427716        0.285134   \n",
       "1      WeightedEnsemble_L2   -0.479886  -0.420161        0.396357   \n",
       "2  RandomForestEntr_BAG_L1   -0.568357  -0.613459        0.053644   \n",
       "3        LightGBMXT_BAG_L1   -0.570314  -0.536182        1.075846   \n",
       "4  RandomForestGini_BAG_L1   -0.618937  -0.533887        0.083508   \n",
       "5   NeuralNetFastAI_BAG_L1   -0.715127  -0.667328        0.642130   \n",
       "6    KNeighborsUnif_BAG_L1   -1.909044  -1.304484        0.012180   \n",
       "7    KNeighborsDist_BAG_L1   -1.953941  -1.315919        0.021935   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.087342  12.252498                 0.285134                0.087342   \n",
       "1       0.154566  14.005736                 0.005780                0.002271   \n",
       "2       0.033299   0.357141                 0.053644                0.033299   \n",
       "3       0.108582  28.633922                 1.075846                0.108582   \n",
       "4       0.057316   0.544376                 0.083508                0.057316   \n",
       "5       0.231859  16.081263                 0.642130                0.231859   \n",
       "6       0.037288   0.009905                 0.012180                0.037288   \n",
       "7       0.007637   0.016894                 0.021935                0.007637   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0          12.252498            1       True          5  \n",
       "1           1.191968            2       True          8  \n",
       "2           0.357141            1       True          7  \n",
       "3          28.633922            1       True          4  \n",
       "4           0.544376            1       True          6  \n",
       "5          16.081263            1       True          3  \n",
       "6           0.009905            1       True          1  \n",
       "7           0.016894            1       True          2  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a multiclass classification using different metric \n",
    "time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "label = 'Embarked'\n",
    "metric = 'log_loss'  # specify your evaluation metric here, most important classification metric based on probabilities, the lower the better\n",
    "presets = 'best_quality' # this allows AutoGluon to automatically construct powerful model ensembles based on stacking/bagging\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets=presets)\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label cannot contain null values\n",
    "train_data['Age'].fillna(value=train_data['Age'].mean(), inplace=True)\n",
    "test_data['Age'].fillna(value=train_data['Age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210709_002645/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210709_002645/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    712\n",
      "Train Data Columns: 7\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (80.0, 0.42, 29.49885, 12.9943)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2089.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1 | ['Fare']\n",
      "\t\t('int', [])    : 4 | ['Survived', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', []) : 2 | ['Sex', 'Embarked']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 2 | ['Sex', 'Embarked']\n",
      "\t\t('float', [])    : 1 | ['Fare']\n",
      "\t\t('int', [])      : 4 | ['Survived', 'Pclass', 'SibSp', 'Parch']\n",
      "\t0.2s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 59.75s of the 59.74s of remaining time.\n",
      "\t-12.4615\t = Validation root_mean_squared_error score\n",
      "\t0.01s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 59.68s of the 59.67s of remaining time.\n",
      "\t-12.5561\t = Validation root_mean_squared_error score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 59.64s of the 59.63s of remaining time.\n",
      "\t-11.1263\t = Validation root_mean_squared_error score\n",
      "\t20.83s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 38.64s of the 38.64s of remaining time.\n",
      "\t-11.1882\t = Validation root_mean_squared_error score\n",
      "\t15.61s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 22.9s of the 22.89s of remaining time.\n",
      "\t-11.8261\t = Validation root_mean_squared_error score\n",
      "\t0.92s\t = Training runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 21.77s of the 21.76s of remaining time.\n",
      "\t-10.8541\t = Validation root_mean_squared_error score\n",
      "\t6.44s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 15.22s of the 15.21s of remaining time.\n",
      "\t-11.886\t = Validation root_mean_squared_error score\n",
      "\t0.78s\t = Training runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 14.18s of the 14.18s of remaining time.\n",
      "\tRan out of time, stopping training early.\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 10.97s of the 10.96s of remaining time.\n",
      "\t-11.1569\t = Validation root_mean_squared_error score\n",
      "\t9.33s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 1.18s of the 1.17s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetMXNet_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency mxnet. A quick tip is to install via `pip install mxnet --upgrade`, or `pip install mxnet_cu101 --upgrade`\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1.16s of the 1.15s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\ttrain_set's rmse: 12.9718\tvalid_set's rmse: 11.8794\n",
      "\tTime limit exceeded... Skipping LightGBMLarge_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.75s of the 0.48s of remaining time.\n",
      "\t-10.8199\t = Validation root_mean_squared_error score\n",
      "\t0.8s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 60.36s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210709_002645/\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-10.752782</td>\n",
       "      <td>-10.854059</td>\n",
       "      <td>0.249982</td>\n",
       "      <td>0.057560</td>\n",
       "      <td>6.438931</td>\n",
       "      <td>0.249982</td>\n",
       "      <td>0.057560</td>\n",
       "      <td>6.438931</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-10.810906</td>\n",
       "      <td>-10.819859</td>\n",
       "      <td>0.716270</td>\n",
       "      <td>0.163994</td>\n",
       "      <td>37.402720</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.800065</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-10.992964</td>\n",
       "      <td>-11.156859</td>\n",
       "      <td>0.338979</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>9.333590</td>\n",
       "      <td>0.338979</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>9.333590</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-11.121413</td>\n",
       "      <td>-11.826139</td>\n",
       "      <td>0.090150</td>\n",
       "      <td>0.143560</td>\n",
       "      <td>0.924472</td>\n",
       "      <td>0.090150</td>\n",
       "      <td>0.143560</td>\n",
       "      <td>0.924472</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-11.174108</td>\n",
       "      <td>-11.188216</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.054497</td>\n",
       "      <td>15.614831</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.054497</td>\n",
       "      <td>15.614831</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-11.302109</td>\n",
       "      <td>-11.886030</td>\n",
       "      <td>0.160024</td>\n",
       "      <td>0.174271</td>\n",
       "      <td>0.776363</td>\n",
       "      <td>0.160024</td>\n",
       "      <td>0.174271</td>\n",
       "      <td>0.776363</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-11.348957</td>\n",
       "      <td>-11.126268</td>\n",
       "      <td>0.117198</td>\n",
       "      <td>0.058346</td>\n",
       "      <td>20.825711</td>\n",
       "      <td>0.117198</td>\n",
       "      <td>0.058346</td>\n",
       "      <td>20.825711</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-11.787222</td>\n",
       "      <td>-12.461454</td>\n",
       "      <td>0.006504</td>\n",
       "      <td>0.018710</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>0.006504</td>\n",
       "      <td>0.018710</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-12.485746</td>\n",
       "      <td>-12.556066</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.008337</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.008337</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val  pred_time_test  \\\n",
       "0         CatBoost_BAG_L1  -10.752782 -10.854059        0.249982   \n",
       "1     WeightedEnsemble_L2  -10.810906 -10.819859        0.716270   \n",
       "2          XGBoost_BAG_L1  -10.992964 -11.156859        0.338979   \n",
       "3  RandomForestMSE_BAG_L1  -11.121413 -11.826139        0.090150   \n",
       "4         LightGBM_BAG_L1  -11.174108 -11.188216        0.092884   \n",
       "5    ExtraTreesMSE_BAG_L1  -11.302109 -11.886030        0.160024   \n",
       "6       LightGBMXT_BAG_L1  -11.348957 -11.126268        0.117198   \n",
       "7   KNeighborsUnif_BAG_L1  -11.787222 -12.461454        0.006504   \n",
       "8   KNeighborsDist_BAG_L1  -12.485746 -12.556066        0.006731   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.057560   6.438931                 0.249982                0.057560   \n",
       "1       0.163994  37.402720                 0.003380                0.000565   \n",
       "2       0.039187   9.333590                 0.338979                0.039187   \n",
       "3       0.143560   0.924472                 0.090150                0.143560   \n",
       "4       0.054497  15.614831                 0.092884                0.054497   \n",
       "5       0.174271   0.776363                 0.160024                0.174271   \n",
       "6       0.058346  20.825711                 0.117198                0.058346   \n",
       "7       0.018710   0.014688                 0.006504                0.018710   \n",
       "8       0.008337   0.004423                 0.006731                0.008337   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           6.438931            1       True          6  \n",
       "1           0.800065            2       True          9  \n",
       "2           9.333590            1       True          8  \n",
       "3           0.924472            1       True          5  \n",
       "4          15.614831            1       True          4  \n",
       "5           0.776363            1       True          7  \n",
       "6          20.825711            1       True          3  \n",
       "7           0.014688            1       True          1  \n",
       "8           0.004423            1       True          2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a regression problem\n",
    "time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "label = 'Age'\n",
    "metric = 'root_mean_squared_error'  # RMSE is the default metric for regression problem\n",
    "presets = 'best_quality' # this allows AutoGluon to automatically construct powerful model ensembles based on stacking/bagging\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets=presets)\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24c36f38f51f2c059798fb8a6f6646f59da8defeb4792367359bef4d1f7f3be9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}